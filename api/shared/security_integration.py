"""
Security Integration Service

Provides integration with Microsoft Defender and Purview for agent security.
Note: Full integration requires appropriate Azure subscriptions and permissions.
"""

import os
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime

logger = logging.getLogger(__name__)


class SecurityIntegrationService:
    """
    Service for integrating with Microsoft security services.
    
    Provides:
    - Defender integration for agent security posture
    - Purview integration for data protection
    - Security recommendations
    - Compliance monitoring
    """
    
    def __init__(self):
        """Initialize security integration service"""
        self.defender_enabled = os.getenv("DEFENDER_ENABLED", "false").lower() == "true"
        self.purview_enabled = os.getenv("PURVIEW_ENABLED", "false").lower() == "true"
        
        # Defender configuration
        self.defender_endpoint = os.getenv("DEFENDER_ENDPOINT")
        self.defender_api_key = os.getenv("DEFENDER_API_KEY")
        
        # Purview configuration
        self.purview_endpoint = os.getenv("PURVIEW_ENDPOINT")
        self.purview_credential = None  # Would use DefaultAzureCredential in production
    
    def check_agent_security_posture(
        self,
        agent_id: str,
        entra_agent_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Check agent security posture using Microsoft Defender.
        
        Args:
            agent_id: Agent identifier
            entra_agent_id: Optional Entra Agent ID (service principal object ID)
            
        Returns:
            Dictionary with security posture information
        """
        if not self.defender_enabled:
            return {
                "status": "not_configured",
                "message": "Microsoft Defender integration not enabled"
            }
        
        # In production, this would call Microsoft Defender API:
        # GET /api/machines/{machineId}/assessments
        # GET /api/servicePrincipals/{id}/vulnerabilities
        
        # For now, return mock data
        return {
            "agent_id": agent_id,
            "entra_agent_id": entra_agent_id,
            "status": "healthy",
            "vulnerabilities": [],
            "recommendations": [],
            "last_scan": datetime.utcnow().isoformat(),
            "message": "Security posture check completed (mock)"
        }
    
    def detect_agent_threats(
        self,
        agent_id: str,
        activity_log: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """
        Detect threats related to agent activities.
        
        Args:
            agent_id: Agent identifier
            activity_log: Optional activity log for analysis
            
        Returns:
            Dictionary with threat detection results
        """
        if not self.defender_enabled:
            return {
                "status": "not_configured",
                "threats": []
            }
        
        # In production, this would:
        # 1. Send activity log to Defender
        # 2. Query threat intelligence
        # 3. Correlate with known attack patterns
        
        threats = []
        
        # Mock threat detection
        if activity_log:
            # Check for suspicious patterns
            for activity in activity_log:
                if activity.get("action") == "unauthorized_access":
                    threats.append({
                        "severity": "high",
                        "type": "unauthorized_access",
                        "description": "Unauthorized access attempt detected",
                        "timestamp": activity.get("timestamp")
                    })
        
        return {
            "agent_id": agent_id,
            "threats": threats,
            "status": "analyzed",
            "timestamp": datetime.utcnow().isoformat()
        }
    
    def classify_agent_data(
        self,
        agent_id: str,
        data_content: str,
        data_type: str = "output"
    ) -> Dict[str, Any]:
        """
        Classify data accessed or generated by an agent using Purview.
        
        Args:
            agent_id: Agent identifier
            data_content: Data content to classify
            data_type: Type of data (input, output, tool_result)
            
        Returns:
            Dictionary with classification results
        """
        if not self.purview_enabled:
            return {
                "status": "not_configured",
                "classification": "unclassified",
                "message": "Microsoft Purview integration not enabled"
            }
        
        # In production, this would call Purview API:
        # POST /scanDataSources/{dataSourceName}/scans/{scanName}/runs
        # GET /scanResults/{scanResultId}/classifications
        
        # Mock classification
        sensitivity_level = "internal"
        if any(keyword in data_content.lower() for keyword in ["password", "secret", "key"]):
            sensitivity_level = "confidential"
        
        return {
            "agent_id": agent_id,
            "data_type": data_type,
            "classification": sensitivity_level,
            "labels": ["internal", "agent-generated"],
            "timestamp": datetime.utcnow().isoformat(),
            "message": "Data classification completed (mock)"
        }
    
    def apply_data_protection(
        self,
        agent_id: str,
        output_text: str,
        classification: Optional[str] = None
    ) -> str:
        """
        Apply data loss prevention (DLP) policies to agent output.
        
        Args:
            agent_id: Agent identifier
            output_text: Output text to protect
            classification: Optional data classification
            
        Returns:
            Protected output text
        """
        if not self.purview_enabled:
            return output_text
        
        # In production, this would:
        # 1. Check DLP policies based on classification
        # 2. Apply redaction or blocking as needed
        # 3. Log DLP actions
        
        # Mock DLP: if classification is confidential, add watermark
        if classification == "confidential":
            return f"[CONFIDENTIAL] {output_text}"
        
        return output_text
    
    def get_security_recommendations(
        self,
        agent_id: str
    ) -> List[Dict[str, Any]]:
        """
        Get security recommendations for an agent.
        
        Args:
            agent_id: Agent identifier
            
        Returns:
            List of security recommendations
        """
        recommendations = []
        
        # Mock recommendations
        recommendations.append({
            "id": "rec-001",
            "title": "Enable MFA for agent identity",
            "description": "Enable multi-factor authentication for the agent's Entra identity",
            "severity": "medium",
            "category": "identity"
        })
        
        recommendations.append({
            "id": "rec-002",
            "title": "Review tool permissions",
            "description": "Regularly review and audit tool permissions granted to the agent",
            "severity": "low",
            "category": "access_control"
        })
        
        return recommendations
    
    def monitor_compliance(
        self,
        agent_id: str,
        compliance_framework: str = "NIST"
    ) -> Dict[str, Any]:
        """
        Monitor agent compliance with security frameworks.
        
        Args:
            agent_id: Agent identifier
            compliance_framework: Compliance framework (NIST, ISO, etc.)
            
        Returns:
            Dictionary with compliance status
        """
        # In production, this would integrate with Purview Compliance Manager
        # or other compliance tools
        
        return {
            "agent_id": agent_id,
            "framework": compliance_framework,
            "compliance_score": 0.85,
            "status": "compliant",
            "findings": [],
            "last_assessment": datetime.utcnow().isoformat(),
            "message": "Compliance monitoring completed (mock)"
        }


# Singleton instance
_security_service: Optional[SecurityIntegrationService] = None


def get_security_service() -> SecurityIntegrationService:
    """Get or create the security integration service instance"""
    global _security_service
    if _security_service is None:
        _security_service = SecurityIntegrationService()
    return _security_service

